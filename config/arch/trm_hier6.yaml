name: recursive_reasoning.trm_hier6@TinyRecursiveModelMultiScale
loss:
  name: losses@ACTLossHead
  loss_type: stablemax_cross_entropy

halt_exploration_prob: 0.1
halt_max_steps: 16

y_cycles: 3  # Number of y update cycles (H_cycles in HRM)
z_cycles: 6  # Number of z recursion steps per y cycle (L_cycles in HRM)

H_layers: 0  # Deprecated (kept for backward compatibility)
num_layers: 2  # Number of layers in the network (L_layers in HRM)

hidden_size: 512
num_heads: 8  # min(2, hidden_size // 64)
expansion: 4

puzzle_emb_ndim: ${.hidden_size}

pos_encodings: rope
forward_dtype: bfloat16

mlp_t: False # use mlp on L instead of transformer
puzzle_emb_len: 16 # if non-zero, its specified to this value
no_ACT_continue: True # No continue ACT loss, only use the sigmoid of the halt which makes much more sense